{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import MNISTtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.7837e+29,  3.0896e-41,  5.7453e-44],\n",
      "        [ 0.0000e+00,         nan,  1.8040e+28],\n",
      "        [ 1.3733e-14,  6.4076e+07,  2.0706e-19],\n",
      "        [ 7.3909e+22,  2.4176e-12,  1.1625e+33],\n",
      "        [ 8.9605e-01,  1.1632e+33,  5.6003e-02]])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "x = torch.Tensor(5, 3)\n",
    "print(x)\n",
    "print(x.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x is un-initialized. The type is torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9321, 0.7039, 0.8556],\n",
      "        [0.0264, 0.7157, 0.0408],\n",
      "        [0.9612, 0.1300, 0.8118],\n",
      "        [0.8288, 0.4323, 0.7953],\n",
      "        [0.9419, 0.7005, 0.4174]])\n",
      "torch.FloatTensor\n",
      "tensor([[ 1.1127e-02, -1.4869e-03, -1.1222e+00],\n",
      "        [ 5.1983e-01, -6.0920e-01,  1.5668e+00],\n",
      "        [ 3.9945e-01,  5.2170e-01,  3.9980e-01],\n",
      "        [ 3.9619e-02,  1.0847e+00,  8.5472e-01],\n",
      "        [ 6.3198e-01, -1.5964e+00, -1.5371e+00]])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "y = torch.rand(5, 3)\n",
    "print(y)\n",
    "print(y.type())\n",
    "y1 = torch.randn(5, 3)\n",
    "print(y1)\n",
    "print(y1.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For rand, the random values is uniform distributed. The type of this y is torch.FloatTensor;\n",
    "For randn, the random values is normal distributed (SD=1, mean=0). The type of this y is torch.FloatTensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.7837e+29,  3.0896e-41,  5.7453e-44],\n",
      "        [ 0.0000e+00,         nan,  1.8040e+28],\n",
      "        [ 1.3733e-14,  6.4076e+07,  2.0706e-19],\n",
      "        [ 7.3909e+22,  2.4176e-12,  1.1625e+33],\n",
      "        [ 8.9605e-01,  1.1632e+33,  5.6003e-02]], dtype=torch.float64)\n",
      "tensor([[0.9321, 0.7039, 0.8556],\n",
      "        [0.0264, 0.7157, 0.0408],\n",
      "        [0.9612, 0.1300, 0.8118],\n",
      "        [0.8288, 0.4323, 0.7953],\n",
      "        [0.9419, 0.7005, 0.4174]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "x = x.double()\n",
    "y = y.double()\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type is torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "x = torch.Tensor([[-0.1859, 1.3970, 0.5236],\n",
    "[ 2.3854, 0.0707, 2.1970],\n",
    "[-0.3587, 1.2359, 1.8951],\n",
    "[-0.1189, -0.1376, 0.4647],\n",
    "[-1.8968, 2.0164, 0.1092]])\n",
    "y = torch.Tensor([[ 0.4838, 0.5822, 0.2755],\n",
    "[ 1.0982, 0.4932, -0.6680],\n",
    "[ 0.7915, 0.6580, -0.5819],\n",
    "[ 0.3825, -1.1822, 1.5217],\n",
    "[ 0.6042, -0.2280, 1.3210]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their shapes are (5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 3])\n",
      "torch.Size([10, 3])\n",
      "torch.Size([5, 6])\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "z = torch.stack((x, y))\n",
    "print(z.shape)\n",
    "\n",
    "z1 = torch.cat((x, y), 0)\n",
    "print(z1.shape)\n",
    "\n",
    "z2 = torch.cat((x, y), 1)\n",
    "print(z2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using stack, the shape is (2,5,3)\n",
    "\n",
    "When using cat((x, y), 0), the shape is (10,3)\n",
    "\n",
    "When using cat((x, y), 1), the shape is (5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y(5,3) =  tensor(1.3210)\n",
      "z(1, 5,3) =  tensor(1.3210)\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "print('y(5,3) = ', y[4,2])\n",
    "print('z(1, 5,3) = ', z[1,4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z(:, 5,3) =  tensor([0.1092, 1.3210])\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "print('z(:, 5,3) = ', z[:, 4,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n",
      "tensor([[ 0.2979,  1.9792,  0.7991],\n",
      "        [ 3.4836,  0.5639,  1.5290],\n",
      "        [ 0.4328,  1.8939,  1.3132],\n",
      "        [ 0.2636, -1.3198,  1.9864],\n",
      "        [-1.2926,  1.7884,  1.4302]])\n"
     ]
    }
   ],
   "source": [
    "# 8\n",
    "print(x + y)\n",
    "print(torch.add(x, y))\n",
    "print(x.add(y))\n",
    "torch.add(x, y, out=x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# 9\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.randn(4,4) generates a (4, 4) torch.tensor via sampling from uniform distribution\n",
    "\n",
    "x.view(16) flattens the (4, 4) tensor to an one dimension array.\n",
    "\n",
    "x.view(-1, 8) reshape the original tensor to an (2, 8) tensor; -1 means that the value is inferred from the length of the array and remaining dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[22.1700, 24.2236]])\n"
     ]
    }
   ],
   "source": [
    "# 10\n",
    "x = torch.rand(10, 10)\n",
    "y = torch.rand(2, 100)\n",
    "x = x.view(1, 100)\n",
    "y = y.view(-1, 2)\n",
    "result = torch.mm(x, y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 11\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(a))\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of a is one dimension (5, ) torch.Tensor.\n",
    "\n",
    "The type of b is one dimension (5, ) numpy.array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 1., 1., 1., 1.])\n",
      "[2. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 12\n",
    "a[0] += 1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are match and they underlying share memory locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 13\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "a[:] += 1\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "a = a.add(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarities: all of the three methods add 1 to all the elements in a.\n",
    "\n",
    "Differences: the first two methods generate matched a and b, which indicates that they a and b are still sharing the same memory location.\n",
    "                  The last methods only influence a but not b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 14\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "First allocation: 0.0008475780487060547\n",
      "Second allocation: 0.00024437904357910156\n"
     ]
    }
   ],
   "source": [
    "# 15   \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'   # let device be 'cuda' only when torch.cuda.is_available() is True; otherwise let device be 'cpu'\n",
    "print(device)\n",
    "s1 = time.time()                   # record the start time 1\n",
    "x = torch.randn(5, 3).to(device)         # generate a (5, 3) tensor and then moved onto GPU\n",
    "e1 = time.time()                   # record the end time 1\n",
    "s2 = time.time()                   # record the start time 2\n",
    "y = torch.randn(5, 3, device=device)   # generate a (5, 3) tensor on GPU\n",
    "e2 = time.time()                   # record the end time 2\n",
    "z = x + y                             # make an addition\n",
    "print('First allocation:', e1 - s1)\n",
    "print('Second allocation:', e2 - s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpretation is in the code comment\n",
    "\n",
    "The second one is the most efficient since it directly generate tensor on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.179279   -0.40430903  0.3379439 ]\n",
      " [-1.0426476   1.168484   -0.32202417]\n",
      " [-0.5972038   0.72707856  0.87745774]\n",
      " [-1.2117367   1.8122796  -0.3585984 ]\n",
      " [-1.9936645   0.7345663   1.3936126 ]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-05999e238feb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# 16\n",
    "print(z.cpu().numpy())   # first transfer z from GPU to CPU and then convert to numpy array\n",
    "print(z.numpy())           # directly convert z(on GPU) to numpy array(on CPU)   It would post an error!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, transfer z from GPU to CPU and then convert to numpy array.\n",
    "\n",
    "Directly converting z(on GPU) to numpy array(on CPU) would post an error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 17\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y)\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The requires grad attribute of y is True.\n",
    "\n",
    "The grad attribute of x and y are None, since there is no backpropogation upon this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# 18\n",
    "z = y * y * 3\n",
    "f = z.mean()\n",
    "print(z, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![WechatIMG241.jpeg](attachment:WechatIMG241.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "# 19\n",
    "f.backward()\n",
    "print(x.grad)  # The gradient of x is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![WechatIMG242.jpeg](attachment:WechatIMG242.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21\n",
    "# training data\n",
    "xtrain, ltrain = MNISTtools.load(dataset=\"training\")\n",
    "# testing data\n",
    "xtest, ltest = MNISTtools.load(dataset=\"testing\")\n",
    "\n",
    "def normalize_MNIST_images(x):\n",
    "    x = x.astype(np.float32)\n",
    "    x = 2*(x/255) - 1\n",
    "    return x\n",
    "\n",
    "xtrain = normalize_MNIST_images(xtrain).astype(np.float32)\n",
    "xtest = normalize_MNIST_images(xtest).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22\n",
    "# reshape\n",
    "xtrain = xtrain.reshape(28,28,1,60000)\n",
    "xtest = xtest.reshape(28,28,1,10000)\n",
    "# move axis\n",
    "xtrain = np.moveaxis(xtrain, [0,1,2,3], [-2, -1, -3, -4])\n",
    "xtest = np.moveaxis(xtest, [0,1,2,3], [-2, -1, -3, -4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lable is: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 23\n",
    "from matplotlib import pyplot\n",
    "pyplot.imshow(xtrain[42, 0, :, :])\n",
    "print('The lable is: '+ str(ltrain[42]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24\n",
    "xtrain = torch.from_numpy(xtrain)\n",
    "ltrain = torch.from_numpy(ltrain)\n",
    "\n",
    "xtest = torch.from_numpy(xtest)\n",
    "ltest = torch.from_numpy(ltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![WechatIMG243.jpeg](attachment:WechatIMG243.jpeg)\n",
    "![WechatIMG244.jpeg](attachment:WechatIMG244.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 26\n",
    "import torch.nn as nn       # This is for importing the baseline class from torch.nn\n",
    "import torch.nn.functional as F       # This is importing necessary functions using in construct neural network\n",
    "# This is our neural networks class that inherits from nn.Module\n",
    "class LeNet(nn.Module): \n",
    "# Here we define our network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()       # This is to inherit attributes and behaviors from nn class without needing to implement them again.\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)       # The first convolution layer\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)       # The second convolution layer\n",
    "        self.fc1 = nn.Linear(256, 120)       # The first fully-connected layer\n",
    "        self.fc2 = nn.Linear(120, 84)       # The second fully-connected layer\n",
    "        self.fc3 = nn.Linear(84, 10)       # The third fully-connected layer\n",
    "    # Here we define one forward pass through the network\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))       # After 1st convolution, process the data via ReLu and then max pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))       # After 2nd convolution, process the data via ReLu and then max pooling\n",
    "        x = x.view(-1, self.num_flat_features(x))       # Flatten the data to 2D\n",
    "        x = F.relu(self.fc1(x))       # After 1st fully-connected layer, process the data via ReLu\n",
    "        x = F.relu(self.fc2(x))       # After 2nd fully-connected layer, process the data via ReLu\n",
    "        x = self.fc3(x)       # Process data via 3rd fully-connected layer\n",
    "        return x\n",
    "    # Determine the number of features in a batch of tensors\n",
    "    def num_flat_features(self, x ):\n",
    "        size = x.size()[1:]       # Get the 2nd, 3rd, and 4th dimension of input tensor\n",
    "        return np.prod(size)       # Product the 2nd, 3rd, 4th dimensions\n",
    "net = LeNet()       # Assign net with the class LeNet\n",
    "print(net)       # Print the architecture of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([6, 1, 5, 5]) True\n",
      "conv1.bias torch.Size([6]) True\n",
      "conv2.weight torch.Size([16, 6, 5, 5]) True\n",
      "conv2.bias torch.Size([16]) True\n",
      "fc1.weight torch.Size([120, 256]) True\n",
      "fc1.bias torch.Size([120]) True\n",
      "fc2.weight torch.Size([84, 120]) True\n",
      "fc2.bias torch.Size([84]) True\n",
      "fc3.weight torch.Size([10, 84]) True\n",
      "fc3.bias torch.Size([10]) True\n"
     ]
    }
   ],
   "source": [
    "# 27\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size(), param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learnable parameters are: conv1.weight, conv1.bias, conv2.weight, conv2.bias, fc1.weight, fc1.bias, fc2.weight, fc2.bias, fc3.weight, fc3.bias.\n",
    "\n",
    "Gradients are going to be tracked by autograd for all above parameters since their requires_grad are True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.7500)\n"
     ]
    }
   ],
   "source": [
    "# 28\n",
    "with torch.no_grad():\n",
    "    yinit = net(xtest)\n",
    "_, lpred = yinit.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result means that the initialized network (without training) can reach an accuracy of 12.75% on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "# 29\n",
    "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
    "    N = xtrain.size()[0] # Training set size\n",
    "    NB = N/B # Number of minibatches\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=gamma, momentum=rho)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.300\n",
      "[1,   200] loss: 2.283\n",
      "[1,   300] loss: 2.257\n",
      "[1,   400] loss: 2.193\n",
      "[1,   500] loss: 1.987\n",
      "[1,   600] loss: 1.519\n",
      "[2,   100] loss: 0.939\n",
      "[2,   200] loss: 0.613\n",
      "[2,   300] loss: 0.433\n",
      "[2,   400] loss: 0.374\n",
      "[2,   500] loss: 0.322\n",
      "[2,   600] loss: 0.278\n",
      "[3,   100] loss: 0.259\n",
      "[3,   200] loss: 0.238\n",
      "[3,   300] loss: 0.221\n",
      "[3,   400] loss: 0.217\n",
      "[3,   500] loss: 0.204\n",
      "[3,   600] loss: 0.187\n"
     ]
    }
   ],
   "source": [
    "# 30\n",
    "def backprop_deep(xtrain, ltrain, net, T, B=100, gamma=.001, rho=.9):\n",
    "    N = xtrain.size()[0] # Training set size\n",
    "    NB = int((N+B-1)/B) # Number of minibatches\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=gamma, momentum=rho)\n",
    "    \n",
    "    for epoch in range(T):\n",
    "        running_loss = 0.0\n",
    "        shuffled_indices = np.random.permutation(range(N))\n",
    "        for k in range(NB):\n",
    "            # Extract k-th minibatch from xtrain and ltrain\n",
    "            minibatch_indices = shuffled_indices[B*k:min(B*(k+1), N)]\n",
    "            inputs = xtrain[minibatch_indices, :, :, :]\n",
    "            labels = ltrain[minibatch_indices]\n",
    "            \n",
    "            # Initialize the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward propagation\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            # Error evaluation\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Back propagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # Parameter update\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print averaged loss per minibatch every 100 mini-batches\n",
    "            # Compute and print statistics\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if k % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                        (epoch + 1, k + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "def weight_reset(m):     # reset net weight\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "        \n",
    "net = LeNet()\n",
    "backprop_deep(xtrain, ltrain, net, T=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(94.6300)\n"
     ]
    }
   ],
   "source": [
    "# 31\n",
    "ypred = net(xtest)\n",
    "_, lpred = ypred.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy improved from 12.75% to 94.63%. The accuracy increases 81.88%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.297\n",
      "[1,   200] loss: 2.282\n",
      "[1,   300] loss: 2.257\n",
      "[1,   400] loss: 2.199\n",
      "[1,   500] loss: 1.987\n",
      "[1,   600] loss: 1.314\n",
      "[2,   100] loss: 0.689\n",
      "[2,   200] loss: 0.517\n",
      "[2,   300] loss: 0.446\n",
      "[2,   400] loss: 0.394\n",
      "[2,   500] loss: 0.353\n",
      "[2,   600] loss: 0.301\n",
      "[3,   100] loss: 0.280\n",
      "[3,   200] loss: 0.264\n",
      "[3,   300] loss: 0.237\n",
      "[3,   400] loss: 0.236\n",
      "[3,   500] loss: 0.223\n",
      "[3,   600] loss: 0.209\n",
      "[4,   100] loss: 0.195\n",
      "[4,   200] loss: 0.184\n",
      "[4,   300] loss: 0.171\n",
      "[4,   400] loss: 0.169\n",
      "[4,   500] loss: 0.161\n",
      "[4,   600] loss: 0.156\n",
      "[5,   100] loss: 0.144\n",
      "[5,   200] loss: 0.150\n",
      "[5,   300] loss: 0.131\n",
      "[5,   400] loss: 0.132\n",
      "[5,   500] loss: 0.133\n",
      "[5,   600] loss: 0.127\n",
      "[6,   100] loss: 0.128\n",
      "[6,   200] loss: 0.119\n",
      "[6,   300] loss: 0.122\n",
      "[6,   400] loss: 0.109\n",
      "[6,   500] loss: 0.112\n",
      "[6,   600] loss: 0.109\n",
      "[7,   100] loss: 0.109\n",
      "[7,   200] loss: 0.097\n",
      "[7,   300] loss: 0.105\n",
      "[7,   400] loss: 0.105\n",
      "[7,   500] loss: 0.100\n",
      "[7,   600] loss: 0.094\n",
      "[8,   100] loss: 0.093\n",
      "[8,   200] loss: 0.099\n",
      "[8,   300] loss: 0.094\n",
      "[8,   400] loss: 0.099\n",
      "[8,   500] loss: 0.084\n",
      "[8,   600] loss: 0.080\n",
      "[9,   100] loss: 0.091\n",
      "[9,   200] loss: 0.086\n",
      "[9,   300] loss: 0.100\n",
      "[9,   400] loss: 0.073\n",
      "[9,   500] loss: 0.073\n",
      "[9,   600] loss: 0.082\n",
      "[10,   100] loss: 0.082\n",
      "[10,   200] loss: 0.074\n",
      "[10,   300] loss: 0.071\n",
      "[10,   400] loss: 0.080\n",
      "[10,   500] loss: 0.076\n",
      "[10,   600] loss: 0.080\n"
     ]
    }
   ],
   "source": [
    "# 32\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "xtrain = xtrain.to(device)\n",
    "ltrain = ltrain.to(device)\n",
    "xtest = xtest.to(device)\n",
    "ltest = ltest.to(device)\n",
    "\n",
    "net.apply(weight_reset)\n",
    "net = LeNet().to(device)\n",
    "\n",
    "backprop_deep(xtrain, ltrain, net, T=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(97.9000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 33\n",
    "ypred = net(xtest)\n",
    "_, lpred = ypred.max(1)\n",
    "print(100 * (ltest == lpred).float().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It improve from 94.63% to 97.90%. The accuracy increases 3.27%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
