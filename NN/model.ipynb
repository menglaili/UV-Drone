{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrResNet18(nn.Module):\n",
    "\n",
    "    def __init__(self, num_actions = 6, fine_tuning = False):\n",
    "        super(CorrResNet18, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=False)\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = fine_tuning\n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        self.avgpool = resnet.avgpool   #  output feature dimension 512 for input image dimension 224*224\n",
    "        self.num_ftrs = resnet.fc.in_features\n",
    "        self.linear_sensor = nn.Linear(5, 128)\n",
    "        self.linear_final = nn.Linear(2*self.num_ftrs+2*128, num_actions)       \n",
    "\n",
    "    def forward(self, img, meta): # image pairs are cat along the channel dimension [batch, 6, width, height]\n",
    "        siam1 = []\n",
    "        siam2 = []\n",
    "        for i in range(2): # the siamese network architecture \n",
    "            # for image\n",
    "            x = self.relu(self.bn1(self.conv1(img[:,(i*3):(i+1)*3, :, :])))\n",
    "            x = self.maxpool(x)\n",
    "            x = self.layer4(self.layer3(self.layer2(self.layer1(x))))\n",
    "            x = self.avgpool(x)\n",
    "            x = x.view(-1, self.num_ftrs)\n",
    "            siam1.append(x)\n",
    "            # for sensor data\n",
    "            y = self.linear_sensor(meta[:,:,i])\n",
    "            siam2.append(y)\n",
    "        out = torch.cat((siam1[0], siam1[1], siam2[0], siam2[1]), dim = 1)\n",
    "        out = self.linear_final(out)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
