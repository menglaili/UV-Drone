{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset preprocess\n",
    "import os\n",
    "import csv\n",
    "import numpy as np \n",
    "\n",
    "train_data_dir = './train_data'\n",
    "train_img_dir = train_data_dir + '/img'\n",
    "train_meta_dir = train_data_dir + '/metadata'\n",
    "train_ctrl_dir = train_data_dir + '/ctrl'\n",
    "\n",
    "scenes = [f.train_ctrl_dir for f in os.scandir(train_ctrl_dir) if f.is_dir()]\n",
    "scenes_num = len(scenes)\n",
    "\n",
    "eval_list = [3]  \n",
    "\n",
    "def minmax(vec, maxval, minval):\n",
    "    return (vec-minval)/(maxval - minval)\n",
    "\n",
    "ctrl_vec_list = []\n",
    "# create a csv to document the file\n",
    "with open('train.csv', 'w') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['ctrl', 'img_exp', 'img_cur', 'meta_exp', 'meta_cur'])    \n",
    "    writer.writeheader()\n",
    "\n",
    "    for scene_idx in range(scenes_num):\n",
    "        if scene_idx in eval_list:\n",
    "            continue\n",
    "        filename = scenes[scene_idx][len(train_ctrl_dir)+1:]\n",
    "        ctrl_subdir = scenes[scene_idx]\n",
    "        img_subdir = os.path.join(train_img_dir, filename)\n",
    "        meta_subdir = os.path.join(train_meta_dir, filename)\n",
    "        sub_ctrl_dir = os.listdir(ctrl_subdir)\n",
    "        # sub_img_dir = os.listdir(img_subdir)\n",
    "        # sub_meta_dir = os.listdir(meta_subdir)\n",
    "        for i in range(len(sub_ctrl_dir)):\n",
    "            # calculate the vector of ctrl\n",
    "            ctrl = np.loadtxt(os.path.join(ctrl_subdir, sub_ctrl_dir[i]))\n",
    "            ctrl_vec_list.append(np.sum(ctrl, 0)[-4:]) # how to normalize the label to 0-1?? use minmax\n",
    "            writer.writerow(\n",
    "            {'ctrl' : os.path.join(ctrl_subdir, str(i)+'vec.txt'), 'img_exp': os.path.join(img_subdir, str(i)+'after.jpg'), \\\n",
    "            'img_cur': os.path.join(img_subdir, str(i)+'err.jpg'), 'meta_exp': os.path.join(meta_subdir, str(i)+'after.txt'), \\\n",
    "            'meta_cur': os.path.join(meta_subdir, str(i)+'err.txt')})\n",
    "\n",
    "\n",
    "with open('val.csv', 'w') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['ctrl', 'img_exp', 'img_cur', 'meta_exp', 'meta_cur'])    \n",
    "    writer.writeheader()\n",
    "    for scene_idx in range(scenes_num):\n",
    "        if scene_idx in eval_list:\n",
    "            filename = scenes[scene_idx][len(train_ctrl_dir)+1:]\n",
    "            ctrl_subdir = scenes[scene_idx]\n",
    "            img_subdir = os.path.join(train_img_dir, filename)\n",
    "            meta_subdir = os.path.join(train_meta_dir, filename)\n",
    "            sub_ctrl_dir = os.listdir(ctrl_subdir)\n",
    "            # sub_img_dir = os.listdir(img_subdir)\n",
    "            # sub_meta_dir = os.listdir(meta_subdir)\n",
    "            for i in range(len(sub_ctrl_dir)):\n",
    "                ctrl = np.loadtxt(os.path.join(ctrl_subdir, sub_ctrl_dir[i]))\n",
    "                ctrl_vec_list.append(np.sum(ctrl, 0)[-4:]) # how to normalize the label to 0-1?? use minmax\n",
    "                writer.writerow(\n",
    "                {'ctrl' : os.path.join(ctrl_subdir, str(i)+'vec.txt'), 'img_exp': os.path.join(img_subdir, str(i)+'after.jpg'), \\\n",
    "                'img_cur': os.path.join(img_subdir, str(i)+'err.jpg'), 'meta_exp': os.path.join(meta_subdir, str(i)+'after.txt'), \\\n",
    "                'meta_cur': os.path.join(meta_subdir, str(i)+'err.txt')})\n",
    "\n",
    "\n",
    "ctrl_vec_list = np.array(ctrl_vec_list)\n",
    "maxval = np.max(ctrl_vec_list, 0)\n",
    "minval = np.min(ctrl_vec_list, 0)\n",
    "for scene_idx in range(scenes_num):\n",
    "    ctrl_subdir = scenes[scene_idx]\n",
    "    sub_ctrl_dir = os.listdir(ctrl_subdir)\n",
    "    for i in range(len(sub_ctrl_dir)):\n",
    "        ctrl = np.loadtxt(os.path.join(ctrl_subdir, sub_ctrl_dir[i]))\n",
    "        np.savetxt(os.path.join(ctrl_subdir, str(i)+'vec.txt'), minmax(np.sum(ctrl, 0)[-4:], maxval, minval))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torchvision as tv\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imgcontroldataset(data.Dataset):\n",
    "    def __init__(self, csv_dir, mode = 'train', image_size = (224, 224)):\n",
    "        super(imgcontroldataset, self).__init__()\n",
    "        self.datacsv = pd.read_csv(os.path.join(csv_dir, \"%s.csv\" % mode))\n",
    "        self.image_size = image_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 3*len(self.datacsv)  # augment the dataset for 3 times, randomness from randomcrop\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx % len(self.datacsv)\n",
    "        \n",
    "        img_cur_path = self.datacsv.iloc[idx]['img_cur']\n",
    "        img_cur = Image.open(img_cur_path).convert('RGB')\n",
    "        img_exp_path = self.datacsv.iloc[idx]['img_exp']\n",
    "        img_exp = Image.open(img_exp_path).convert('RGB')  \n",
    "        meta_cur_path = self.datacsv.iloc[idx]['meta_cur']\n",
    "        meta_cur = np.loadtxt(meta_cur_path)\n",
    "        meta_exp_path = self.datacsv.iloc[idx]['meta_exp']\n",
    "        meta_exp = np.loadtxt(meta_exp_path)\n",
    "        ctrl_path = self.datacsv.iloc[idx]['ctrl']\n",
    "        ctrl = np.loadtxt(ctrl_path)\n",
    "        \n",
    "        # img transformation\n",
    "        transform = tv.transforms.Compose([        \n",
    "            tv.transforms.Resize(min(image_size)),    # fix the ratio and keep the smaller edge to 224 according to Relative **\n",
    "            tv.transforms.RandomCrop(image_size),\n",
    "            tv.transforms.ColorJitter(),  # randomly change hue, contrast illumination\n",
    "            tv.transforms.ToTensor(),    \n",
    "            tv.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),    # copied from pytorch tutorial imagenet\n",
    "            ])\n",
    "        img1 = transform(img_exp)\n",
    "        img2 = transform(img_cur)\n",
    "        img = torch.cat((img1, img2), dim = 0)  # The dimension 0 is the RGB channel\n",
    "        meta = torch.cat((torch.from_numpy(meta_exp)[:, None], torch.from_numpy(meta_cur)[:, None]), dim = 1)\n",
    "        ctrl = torch.from_numpy(ctrl)\n",
    "        \n",
    "        return img, meta, ctrl\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
